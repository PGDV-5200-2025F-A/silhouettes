{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"hf://datasets/RevolutionCrossroads/si_us_revolutionary_era_collections/si_revwar.parquet\")\n",
    "\n",
    "sil_df = df[df.apply(lambda row: len(row[\"mediaURLs\"]) == 1 and \"silhouette\" in str(row[\"indexed_object_types\"]).lower(), axis=1)].copy()\n",
    "\n",
    "sil_df[\"id\"] = sil_df.apply(lambda row: f\"000000{row.name}\"[-5:], axis=1)\n",
    "sil_df[\"imageURL\"] = sil_df[\"mediaURLs\"].apply(lambda x: x[0])\n",
    "\n",
    "sil_df[[\"id\", \"EDANid\", \"imageURL\", \"thumbnail\"]].to_csv(\"./image/rev-sils/sils_info.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "def save_img(image_url, fpath):\n",
    "  img_data = requests.get(image_url).content\n",
    "  with open(fpath, \"wb\") as handler:\n",
    "    handler.write(img_data)\n",
    "\n",
    "df = pd.read_csv(\"./image/rev-sils/sils_info.csv\", dtype={\"id\": str})\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "  fpath = f\"./image/rev-sils/00_orig/{row['id']}.jpg\"\n",
    "  save_img(row[\"img_url\"], fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop images and save raw contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image as PImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contour_is_valid(c, h, w, m=1):\n",
    "  for p in c:\n",
    "    x, y = p[0]\n",
    "    if x < m or x > w - m - 1 or y < m or y > h - m - 1:\n",
    "      return False\n",
    "  return cv2.contourArea(c) < 0.80 * h * w\n",
    "\n",
    "center_r = 10\n",
    "thold_pad = 64\n",
    "\n",
    "df = pd.read_csv(\"./image/rev-sils/sils_info.csv\", dtype={\"id\": str})\n",
    "\n",
    "contour_data_cropped_raw = []\n",
    "\n",
    "for idx,row in list(df.iterrows()):\n",
    "  img = PImage.open(f\"./image/rev-sils/01_fixed/{row['id']}.jpg\")\n",
    "  oimg = PImage.open(f\"./image/rev-sils/00_orig/{row['id']}.jpg\")\n",
    "  iw,ih = img.size\n",
    "\n",
    "  img_np = np.array(img.resize((iw//4, ih//4)))\n",
    "  nph,npw,_ = img_np.shape\n",
    "\n",
    "  center = img_np[nph//2-center_r:nph//2+center_r+1, npw//2-center_r:npw//2+center_r+1]\n",
    "  center_avg = int(center.mean())\n",
    "\n",
    "  ret, img_t_np = cv2.threshold(cv2.cvtColor(img_np, cv2.COLOR_BGR2GRAY), center_avg+thold_pad, 255, cv2.THRESH_BINARY)\n",
    "  contours, hierarchy = cv2.findContours(image=img_t_np, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "  if contours:\n",
    "    filtered_contours = [c for c in contours if contour_is_valid(c, nph, npw)]\n",
    "    largest_contour = max(filtered_contours, key=cv2.contourArea)\n",
    "\n",
    "    bx, by, bw, bh = cv2.boundingRect(largest_contour)\n",
    "    # cv2.drawContours(img_np, [largest_contour], -1, (0, 255, 0), 1)\n",
    "    # cv2.rectangle(img_np, (bx, by), (bx + bw, by + bh), (0, 0, 255), 2)\n",
    "\n",
    "    cropped = oimg.crop((4*bx, 4*by, 4*(bx+bw), 4*(by+bh)))\n",
    "    cw, ch = cropped.size\n",
    "\n",
    "    if cw > 255 and ch > 255:\n",
    "      cropped.save(f\"./image/rev-sils/02_cropped/{row['id']}.jpg\")\n",
    "      contour_data_cropped_raw.append({\n",
    "        \"id\": row[\"id\"],\n",
    "        \"EDANid\": row[\"EDANid\"],\n",
    "        \"imageURL\": row[\"imageURL\"],\n",
    "        \"thumbnail\": row[\"thumbnail\"],\n",
    "        \"crop\": [4*bx, 4*by, 4*bw, 4*bh],\n",
    "        \"contour\": [[int(px-bx)*4, int(py-by)*4] for px,py in largest_contour.reshape(-1, 2).tolist()]\n",
    "      })\n",
    "    else:\n",
    "      oimg.save(f\"./image/rev-sils/02_cropped/fail/{row['id']}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./image/rev-sils/sils_cropped_raw.json\", \"w\") as ofp:\n",
    "  json.dump(contour_data_cropped_raw, ofp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export images with consistent height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image as PImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./image/rev-sils/sils_cropped_raw.json\", \"r\") as ifp:\n",
    "  contour_data_cropped_raw = json.load(ifp)\n",
    "\n",
    "min_x, min_y, min_w, min_h = np.array([x[\"crop\"] for x in contour_data_cropped_raw]).min(axis=0)\n",
    "\n",
    "for img in contour_data_cropped_raw:\n",
    "  sid = img[\"id\"]\n",
    "  img = PImage.open(f\"./image/rev-sils/02_cropped/{sid}.jpg\")\n",
    "  iw,ih = img.size\n",
    "  nw = int(iw/ih * min_h)\n",
    "  img.resize((nw, min_h)).save(f\"./image/rev-sils/03_sized/{sid}.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load contours for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./image/rev-sils/sils_cropped_raw.json\", \"r\") as ifp:\n",
    "  contour_data_cropped_raw = json.load(ifp)\n",
    "\n",
    "min_contour_len = min([len(c) for c in [x[\"contour\"] for x in contour_data_cropped_raw]])\n",
    "\n",
    "ids = np.array([x[\"id\"] for x in contour_data_cropped_raw]).reshape(-1,1)\n",
    "record_info = np.array([[x[k] for k in [\"EDANid\",\"imageURL\",\"thumbnail\"]] for x in contour_data_cropped_raw])\n",
    "crop_info = np.array([x[\"crop\"] for x in contour_data_cropped_raw])\n",
    "sil_info = np.concatenate((ids, record_info, crop_info), axis=1)\n",
    "sil_info_df = pd.DataFrame(sil_info, columns=[\"id\",\"EDANid\",\"imageURL\",\"thumbnail\",\"cx\",\"cy\",\"cw\",\"ch\"])\n",
    "\n",
    "print(min_contour_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_angle(points):\n",
    "  cx,cy = points.mean(axis=0)\n",
    "  return np.array(sorted(points, key=lambda A: 100*np.arctan2(A[1]-cy, A[0]-cx) + ((A[1]-cy)**2 + (A[0]-cx)**2)**0.5))\n",
    "\n",
    "def center_points_1d(points):\n",
    "  avg = (points.max() + points.min()) / 2\n",
    "  return points - avg\n",
    "\n",
    "def center_points_2d(points, flatten=False):\n",
    "  x_points_centered = center_points_1d(points[:, 0])\n",
    "  y_points_centered = center_points_1d(points[:, 1])\n",
    "  if flatten:\n",
    "    return np.stack((x_points_centered, y_points_centered), axis=1).reshape(-1)\n",
    "  else:\n",
    "    return np.stack((x_points_centered, y_points_centered), axis=1)\n",
    "\n",
    "contour_data = []\n",
    "for img in contour_data_cropped_raw:\n",
    "  cbx,cby,cbw,cbh = img[\"crop\"]\n",
    "  contour = np.array(img[\"contour\"]) / max(cbw,cbh)\n",
    "\n",
    "  kmeans = KMeans(n_clusters=min_contour_len, random_state=1010).fit(contour)\n",
    "  \n",
    "  contour_idxs, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, contour)\n",
    "  contour_points = contour[contour_idxs]\n",
    "\n",
    "  contour_data.append(center_points_2d(sort_by_angle(contour_points), flatten=True))\n",
    "\n",
    "contour_data_np = np.array(contour_data)\n",
    "contour_data_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_col_names = np.array([(f\"x{i}\", f\"y{i}\") for i in range(contour_data_np.shape[1]//2)]).reshape(-1).tolist()\n",
    "sil_con_df = pd.DataFrame(contour_data_np, columns=con_col_names).astype(float).round(6)\n",
    "\n",
    "pd.concat([sil_info_df, sil_con_df], axis=1).to_csv(\"./csv/rev_sils_centered.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read centered `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from PIL import Image as PImage, ImageDraw as PImageDraw\n",
    "\n",
    "non_xy_cols = [\"id\",\"EDANid\",\"imageURL\",\"thumbnail\",\"cx\",\"cy\",\"cw\",\"ch\"]\n",
    "sil_df = pd.read_csv(\"./csv/rev_sils_centered.csv\", dtype={\"id\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1200\n",
    "sid = sil_df.iloc[idx][\"id\"]\n",
    "cx,cy,cw,ch = sil_df.iloc[idx][[\"cx\",\"cy\",\"cw\",\"ch\"]]\n",
    "cxys = sil_df.iloc[[idx]].drop(columns=non_xy_cols).values.reshape(-1,2)\n",
    "\n",
    "oimg = PImage.open(f\"./image/rev-sils/00_orig/{sid}.jpg\")\n",
    "display(oimg.crop((cx,cy,cx+cw,cy+ch)))\n",
    "\n",
    "img = PImage.open(f\"./image/rev-sils/03_sized/{sid}.jpg\")\n",
    "iw,ih = img.size\n",
    "max_dim = max(iw, ih)\n",
    "draw = PImageDraw.Draw(img)\n",
    "\n",
    "for x,y in cxys:\n",
    "  px = x * max_dim + iw//2\n",
    "  py = y * max_dim + ih//2\n",
    "  r = 2\n",
    "  draw.ellipse((px-r, py-r, px+r, py+r), fill=(255,0,0))\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_cxys = sil_df.drop(columns=non_xy_cols).mean().values.reshape(-1,2)\n",
    "\n",
    "img = PImage.fromarray(255*np.ones(shape=(256,256,3), dtype=np.uint8))\n",
    "iw,ih = img.size\n",
    "max_dim = max(iw, ih)\n",
    "draw = PImageDraw.Draw(img)\n",
    "\n",
    "for x,y in avg_cxys:\n",
    "  px = x * max_dim + iw//2\n",
    "  py = y * max_dim + ih//2\n",
    "  r = 2\n",
    "  draw.ellipse((px-r, py-r, px+r, py+r), fill=(255,0,0))\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_vals = sil_df.drop(columns=non_xy_cols).values\n",
    "\n",
    "sized_h = 972\n",
    "n_clusters = 8\n",
    "n_imgs_per_cluster = 16\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=1010).fit(contour_vals)\n",
    "\n",
    "for cidx in range(n_clusters):\n",
    "  aimg = PImage.fromarray(255*np.ones((sized_h,640,3), dtype=np.uint8))\n",
    "  aiw,aih = aimg.size\n",
    "  draw = PImageDraw.Draw(aimg)\n",
    "\n",
    "  cur_x = 0\n",
    "  crows = sil_df.iloc[kmeans.labels_ == cidx]\n",
    "  dists = np.linalg.norm(contour_vals[kmeans.labels_ == cidx] - kmeans.cluster_centers_[cidx], axis=1)\n",
    "  top_contours = crows.iloc[np.argsort(dists)]\n",
    "\n",
    "  cavg = contour_vals[kmeans.labels_ == cidx].mean(axis=0).reshape(-1,2)\n",
    "\n",
    "  for x,y in cavg:\n",
    "    px = x * sized_h + aiw//2\n",
    "    py = y * sized_h + aih//2\n",
    "    r = 2\n",
    "    draw.ellipse((px-r, py-r, px+r, py+r), fill=(0,0,0))\n",
    "\n",
    "  cimg = np.zeros((sized_h, n_imgs_per_cluster*sized_h, 3), dtype=np.uint8)\n",
    "  cimg[:, cur_x:cur_x+aiw] = np.array(aimg)\n",
    "\n",
    "  cur_x = aiw\n",
    "  for sid in top_contours[\"id\"][:n_imgs_per_cluster]:\n",
    "    img = PImage.open(f\"./image/rev-sils/03_sized/{sid}.jpg\")\n",
    "    iw,ih = img.size\n",
    "    cimg[:, cur_x:cur_x+iw] = np.array(img)\n",
    "    cur_x += iw\n",
    "\n",
    "  display(PImage.fromarray(cimg).crop((0,0, cur_x, sized_h)))\n",
    "  # PImage.fromarray(cimg).crop((0,0, cur_x, sized_h)).resize((int(cur_x/sized_h*300), 300)).save(f\"km_{n_clusters}_{cidx}.jpg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push to Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from datasets import Dataset, Image\n",
    "\n",
    "sil_df = pd.read_csv(\"./csv/rev_sils_centered.csv\", dtype={\"id\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {\n",
    "  \"original\": \"./image/rev-sils/00_orig\",\n",
    "  \"fixed\": \"./image/rev-sils/01_fixed\",\n",
    "  \"cropped\": \"./image/rev-sils/02_cropped\",\n",
    "  \"sized\": \"./image/rev-sils/03_sized\"\n",
    "}\n",
    "\n",
    "def get_col_vals(data, col):\n",
    "  return [x[col] for x in data]\n",
    "\n",
    "xcols = [x for x in sil_df.columns if x.startswith(\"x\")]\n",
    "ycols = [y for y in sil_df.columns if y.startswith(\"y\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split,img_dir in splits.items():\n",
    "  print(\"preparing:\", split)\n",
    "\n",
    "  sil_int_df = sil_df.copy()\n",
    "  if split in [\"original\", \"fixed\"]:\n",
    "    sil_int_df[xcols] = sil_int_df.apply(lambda r: r[\"cx\"] + r[\"cw\"] / 2 + r[xcols] * r[\"ch\"], axis=1).round().astype(int)\n",
    "    sil_int_df[ycols] = sil_int_df.apply(lambda r: r[\"cy\"] + r[\"ch\"] / 2 + r[ycols] * r[\"ch\"], axis=1).round().astype(int)\n",
    "  elif split == \"cropped\":\n",
    "    sil_int_df[xcols] = sil_int_df.apply(lambda r: r[\"cw\"] / 2 + r[xcols] * r[\"ch\"], axis=1).round().astype(int)\n",
    "    sil_int_df[ycols] = sil_int_df.apply(lambda r: r[\"ch\"] / 2 + r[ycols] * r[\"ch\"], axis=1).round().astype(int)\n",
    "  elif split == \"sized\":\n",
    "    sized_h = 972\n",
    "    sil_int_df[xcols] = sil_int_df.apply(lambda r: sized_h / r[\"ch\"] * r[\"cw\"] / 2 + r[xcols] * sized_h, axis=1).round().astype(int)\n",
    "    sil_int_df[ycols] = sil_int_df.apply(lambda r: sized_h / 2 + r[ycols] * sized_h, axis=1).round().astype(int)\n",
    "\n",
    "  sil_json = []\n",
    "  for idx,row in sil_int_df.iterrows():\n",
    "    img_info = {k:row[k] for k in sil_int_df.columns}\n",
    "    img_info[\"image\"] = f\"{img_dir}/{row['id']}.jpg\"\n",
    "    sil_json.append(img_info)\n",
    "\n",
    "  print(\"creating data\")\n",
    "  data = {col: get_col_vals(sil_json, col) for col in sil_json[0].keys()}\n",
    "\n",
    "  print(\"creating Dataset\")\n",
    "  dataset = Dataset.from_dict(data)\n",
    "\n",
    "  print(\"opening images\")\n",
    "  dataset = dataset.cast_column(\"image\", Image())\n",
    "\n",
    "  print(\"pushing\")\n",
    "  dataset.push_to_hub(\"visualizedata/revolutionary_silhouettes\", split=split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add original images to repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"HF_HUB_DISABLE_XET\"] = \"1\"\n",
    "\n",
    "from PIL import Image as PImage, ImageDraw as PImageDraw\n",
    "from datasets import Dataset, Image, load_dataset\n",
    "\n",
    "original_ds = load_dataset(\"visualizedata/revolutionary_silhouettes\", split=\"original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in original_ds:\n",
    "  img = s[\"image\"]\n",
    "  img.save(f\"./imgs/00_original/{s['id']}.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add silhouette images to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from PIL import Image as PImage, ImageDraw as PImageDraw\n",
    "from datasets import Dataset, Image, load_dataset\n",
    "\n",
    "original_ds = load_dataset(\"visualizedata/revolutionary_silhouettes\", split=\"original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = 6\n",
    "sil_json = []\n",
    "\n",
    "for s in original_ds:\n",
    "  iw,ih = s[\"image\"].size\n",
    "  img_info = {k:s[k] for k in s.keys() if k != \"image\"}\n",
    "  img = PImage.fromarray(np.zeros((ih, iw, 4), dtype=np.uint8))\n",
    "  draw = PImageDraw.Draw(img)\n",
    "\n",
    "  xs = [s[c] for c in s.keys() if c.startswith(\"x\")]\n",
    "  ys = [s[c] for c in s.keys() if c.startswith(\"y\")]\n",
    "  for x,y in zip(xs,ys):\n",
    "    draw.ellipse((x-pr,y-pr,x+pr,y+pr), fill=(255,255,255,255))\n",
    "\n",
    "  img_info[\"image\"] = img\n",
    "  sil_json.append(img_info)\n",
    "\n",
    "def get_col_vals(data, col):\n",
    "  return [x[col] for x in data]\n",
    "\n",
    "print(\"creating data\")\n",
    "data = {col: get_col_vals(sil_json, col) for col in sil_json[0].keys()}\n",
    "\n",
    "print(\"creating Dataset\")\n",
    "dataset = Dataset.from_dict(data)\n",
    "\n",
    "print(\"opening images\")\n",
    "dataset = dataset.cast_column(\"image\", Image())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pushing\")\n",
    "dataset.push_to_hub(\"visualizedata/revolutionary_silhouettes\", split=\"silhouetted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with Smithsonian (add filename to full data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./json/dataset_silhouettes_only.json\", \"r\") as ifp:\n",
    "  si_data = json.load(ifp)\n",
    "\n",
    "with open(\"./json/edan2id.json\", \"r\") as ifp:\n",
    "  edan2id = json.load(ifp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for si_rec in si_data:\n",
    "  si_edan = si_rec[\"EDANurl\"]\n",
    "  if si_edan not in edan2id:\n",
    "    print(si_edan, \"has no filename\")\n",
    "  else:\n",
    "    si_rec[\"filename\"] = edan2id[si_edan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./json/dataset_silhouettes_only_with_filename.json\", \"w\") as ofp:\n",
    "  json.dump(si_data, ofp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from io import BytesIO\n",
    "from PIL import Image as PImage\n",
    "\n",
    "CSV_URL = \"https://huggingface.co/datasets/visualizedata/revolutionary_silhouettes/raw/main/csv/revolutionary_silhouettes-original.csv\"\n",
    "\n",
    "def get_img(url):\n",
    "  res = requests.get(url, timeout=10)\n",
    "  res.raise_for_status()\n",
    "  return PImage.open(BytesIO(res.content)).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(CSV_URL, dtype={\"id\": str})\n",
    "\n",
    "x_columns = [c for c in df.columns if c.startswith(\"x\")]\n",
    "y_columns = [c for c in df.columns if c.startswith(\"y\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first image x and y values, image url and id\n",
    "xs = [df.loc[0, c] for c in x_columns]\n",
    "ys = [df.loc[0, c] for c in y_columns]\n",
    "imgURL = df.loc[0, \"imageURL\"]\n",
    "id = df.loc[0, \"id\"]\n",
    "\n",
    "# open image for size\n",
    "img = get_img(imgURL)\n",
    "iw,ih = img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svg_txt = f'<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 {iw} {ih}\">\\n'\n",
    "\n",
    "for xc,yc in zip(x_columns, y_columns):\n",
    "  x = df.loc[0, xc]\n",
    "  y = df.loc[0, yc]\n",
    "  svg_txt += f'  <circle cx=\"{x}\" cy=\"{y}\" r=\"5\" fill=\"rgb(200,0,0)\" stroke=\"none\" />\\n'\n",
    "\n",
    "svg_txt += '</svg>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{id}.svg\", \"w\") as ofp:\n",
    "  ofp.write(svg_txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "5020",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
